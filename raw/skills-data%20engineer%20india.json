{"search_metadata": {"id": "643ba5cfc90e0a7a2c1e6459", "status": "Success", "json_endpoint": "https://serpapi.com/searches/3bbe5f91b5182364/643ba5cfc90e0a7a2c1e6459.json", "created_at": "2023-04-16 07:37:51 UTC", "processed_at": "2023-04-16 07:37:51 UTC", "google_jobs_url": "https://www.google.com/search?q=data%20engineer%20india&ibp=htl;jobs&hl=en", "raw_html_file": "https://serpapi.com/searches/3bbe5f91b5182364/643ba5cfc90e0a7a2c1e6459.html", "total_time_taken": 1.8}, "search_parameters": {"q": "data%20engineer%20india", "engine": "google_jobs", "google_domain": "google.com", "hl": "en"}, "jobs_results": [{"title": "Sr. Data Engineer", "company_name": "Clairvoyant", "location": " Anywhere ", "via": "via Glassdoor", "description": "\u2022 Job type:FTE/W2\n\u2022 Location: Remote\n...\nJOB DESCRIPTION:\n\u2022 Must have 6+ Years of experience as Data Engineer\n\u2022 Solid experience in pyspark & SQL\n\u2022 Experience working with AWS services (S3, EMR) and Databricks platform\n\u2022 Following skills are important to have:\n\u2022 SQL\n\nPython,Spark,MDM (Master Data Management),QA/ UAT,Cloud\n\nJob Type: Full-time\n\nSalary: $120,000.00 - $140,000.00 per year\n\nSchedule:\n\u2022 Monday to Friday\n\nExperience:\n\u2022 Master data management: 3 years (Required)\n\u2022 sql: 6 years (Required)\n\u2022 Python: 5 years (Required)\n\u2022 QA: 3 years (Required)\n\u2022 AWS: 4 years (Required)\n\u2022 Spark: 3 years (Required)\n\nWork Location: Remote", "job_highlights": [{"title": "Qualifications", "items": ["Must have 6+ Years of experience as Data Engineer", "Solid experience in pyspark & SQL", "Experience working with AWS services (S3, EMR) and Databricks platform", "Master data management: 3 years (Required)", "sql: 6 years (Required)", "Python: 5 years (Required)", "QA: 3 years (Required)", "AWS: 4 years (Required)", "Spark: 3 years (Required)"]}, {"title": "Benefits", "items": ["Salary: $120,000.00 - $140,000.00 per year"]}], "related_links": [{"link": "https://www.google.com/search?ucbcb=1&hl=en&q=Clairvoyant&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCMsJ", "text": "See web results for Clairvoyant"}], "extensions": ["3 days ago", "120K\u2013140K a year", "Work from home", "Full-time", "No degree mentioned"], "detected_extensions": {"posted_at": "3 days ago", "schedule_type": "Full-time", "salary": "120K\u2013140K a year", "work_from_home": true}, "job_id": "eyJqb2JfdGl0bGUiOiJTci4gRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiMGtIU1FUSUpTOThBQUFBQUFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXVJQkNxSUJRVVZ6TjJwT1V6TTFhUzFUWjBSR2JHRXhjVTlMVkY5bVVsQjJVbVIxYzA5dGNHaEJhMEZPTVVSbGNqYzJjM2xhZFVSME0xOXFhazlGTW5OeVIzTmFTa2hvYkVKTFlWUmZXVVpIYUZaZlJGZHJNV05oUnpBek1GQjRNRkJXY2w5bExTMXphVjlJWW5CMFFuWlBWSE56TjJwQ1dXZFdjeTFUYUVoYVdqQkZRMko1TkZCU1pVRjJlalV0TVVKVFpHWkliMUJ1WlRaaGRWSlRaakYyWlRSdVZWcDNFaGN3UzFVM1drcFVTRTQzTjBaclVFbFFNbDlwVEMxQk5Cb2lRVTh0TUhKc04wdDRjVjlmYzB0NllVRlJjR0ZyV0VOaFVteG1TVVU1Y0RSd1FRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiIubkZnMmVie2ZvbnQtd2VpZ2h0OjUwMH0uQmk2RGRje2ZvbnQtd2VpZ2h0OjUwMH1BcHBseSBkaXJlY3RseSBvbiBHbGFzc2Rvb3IiLCJsaW5rIjoiaHR0cHM6Ly93d3cuZ2xhc3Nkb29yLmNvbS9qb2ItbGlzdGluZy9zci1kYXRhLWVuZ2luZWVyLWNsYWlydm95YW50LUpWX0tPMCwxNl9LRTE3LDI4Lmh0bT9qbD0xMDA4NTg2NjczNjcwXHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="}, {"title": "Staff Data Engineer \u2013 Analytics", "company_name": "Visa", "location": "  United States   ", "via": "via Salary.com", "description": "Company Description\n\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals... businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone.\n\nJob Description\n\nVerifi a Visa entity operates a network enabling data sharing among Acquirers, Merchants & Issuers for fraud prevention, dispute prevention and revenue recovery. Below are the key product solutions which are managed by this technology team . Card Holder Dispute Resolution Network (CDRN) - Resolve pre-dispute cases directed by participating CDRN issuers. Intelligence Suite - Risk management platform that allows merchant to customize services to protect their business, gain greater customer insights and seamlessly keep pace with emerging fraud threats The Verifi reporting and analytics team is responsible for all facets of architecture, software development and production support of data pipelines, ETL process, reporting and analytics system. The reporting and analytics team support Visa's Business users in Billing, Client Services, Issuer Processing and Global Contact Center Teams in providing access to data and insights from multiple applications. As a Staff Data Engineer supporting reporting and analytics group, you will be responsible for mentoring the analytics talent, keeping the team highly engaged and motivated while delivering exceptional results. Your ability to work across functions and teams will allow you to drive results and foster the right culture and environment to achieve Engineering Excellence and Innovation. You will be responsible for working with product development, quality engineering, security engineering, enterprise operations and other internal and external technology partners to deliver products for business integration & enablement. Responsibilities Work with Business stakeholders to understand Business requirements and desired business outcomes Understand OLTP application and data, gain functional understanding and work on conceptual design of data pipelines and Dashboards/reports. Assist in scoping and designing Analytic data assets, implementing modelled attributes, and contributing to brainstorming sessions. Build complex dashboards/reports using the Power BI, Tableau and SSAS. Build and support various ad-hoc reports generated from heterogeneous database. Ensure project delivery within timelines and budget requirements. Perform other tasks like researching new data sources, data governance, system infrastructure, analytics tool evaluation, and other cross team functions, on an as-needed basis. Build monitoring and alerting for the reporting and analytics system. Seek prospects for consolidating various reporting systems and build centralized reporting system that caters various needs. Integrate reporting system with Jenkins for automated deployment. Find opportunities to create, automate and scale repeatable analysis or build self-service tools for business users Present analysis results or insights from data to Business stakeholders Execute data engineering projects ranging from small to large either individually or as part of a project team Support, debug, and fix issues in Production This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.\n\nQualifications\n\n\u2022 10 years of work experience with a bachelor\u2019s degree or at least 8 years of work experience with a master\u2019s degree \u2022 Hands on experience in building analytical report dashboards using Microsoft Technologies (SQL Server, Power BI, Analysis services) to solve business problems \u2022 Strong Data analysis and SQL expertise and understanding of DWH data models required \u2022 Work experience in the ETL tool like clover is preferred along with the exposure to Java. \u2022 Experience with data visualization and business intelligence tools like Power BI, Tableau or other BI tools required. \u2022 Good to have the exposure to the data replication tools like Qlik replicate. \u2022 Experience using DAX functions, building Power BI data models required \u2022 Experience with embedding dashboards in Power apps, Power Automate, Azure Cloud components nice to have \u2022 Experience working in a scrum team owning end to end solutions \u2022 Presentation skills and good communication skills presenting insights to Business is highly desired. \u2022 Familiarity or experience with data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.) is nice to have \u2022 Previous exposure to financial services, credit cards or merchant analytics is a plus, but not required. \u2022 Strategic thinker and good business acumen to orient data engineering to the business needs of internal clients. \u2022 Demonstrated analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style.\n\nAdditional Information\n\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law", "job_highlights": [{"title": "Qualifications", "items": ["10 years of work experience with a bachelor\u2019s degree or at least 8 years of work experience with a master\u2019s degree", "Hands on experience in building analytical report dashboards using Microsoft Technologies (SQL Server, Power BI, Analysis services) to solve business problems", "Strong Data analysis and SQL expertise and understanding of DWH data models required", "Experience with data visualization and business intelligence tools like Power BI, Tableau or other BI tools required", "Good to have the exposure to the data replication tools like Qlik replicate", "Experience using DAX functions, building Power BI data models required", "Experience with embedding dashboards in Power apps, Power Automate, Azure Cloud components nice to have", "Experience working in a scrum team owning end to end solutions", "Familiarity or experience with data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.) is nice to have", "Strategic thinker and good business acumen to orient data engineering to the business needs of internal clients", "Demonstrated analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style"]}, {"title": "Responsibilities", "items": ["Intelligence Suite - Risk management platform that allows merchant to customize services to protect their business, gain greater customer insights and seamlessly keep pace with emerging fraud threats The Verifi reporting and analytics team is responsible for all facets of architecture, software development and production support of data pipelines, ETL process, reporting and analytics system", "The reporting and analytics team support Visa's Business users in Billing, Client Services, Issuer Processing and Global Contact Center Teams in providing access to data and insights from multiple applications", "As a Staff Data Engineer supporting reporting and analytics group, you will be responsible for mentoring the analytics talent, keeping the team highly engaged and motivated while delivering exceptional results", "Your ability to work across functions and teams will allow you to drive results and foster the right culture and environment to achieve Engineering Excellence and Innovation", "You will be responsible for working with product development, quality engineering, security engineering, enterprise operations and other internal and external technology partners to deliver products for business integration & enablement", "Responsibilities Work with Business stakeholders to understand Business requirements and desired business outcomes Understand OLTP application and data, gain functional understanding and work on conceptual design of data pipelines and Dashboards/reports", "Assist in scoping and designing Analytic data assets, implementing modelled attributes, and contributing to brainstorming sessions", "Build complex dashboards/reports using the Power BI, Tableau and SSAS", "Build and support various ad-hoc reports generated from heterogeneous database", "Ensure project delivery within timelines and budget requirements", "Perform other tasks like researching new data sources, data governance, system infrastructure, analytics tool evaluation, and other cross team functions, on an as-needed basis", "Build monitoring and alerting for the reporting and analytics system", "Seek prospects for consolidating various reporting systems and build centralized reporting system that caters various needs", "Integrate reporting system with Jenkins for automated deployment", "Find opportunities to create, automate and scale repeatable analysis or build self-service tools for business users Present analysis results or insights from data to Business stakeholders Execute data engineering projects ranging from small to large either individually or as part of a project team Support, debug, and fix issues in Production This is a hybrid position"]}], "related_links": [{"link": "http://usa.visa.com/", "text": "usa.visa.com"}, {"link": "https://www.google.com/search?ucbcb=1&hl=en&q=Visa&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCJEK", "text": "See web results for Visa"}], "extensions": ["Full-time"], "detected_extensions": {"schedule_type": "Full-time"}, "job_id": "eyJqb2JfdGl0bGUiOiJTdGFmZiBEYXRhIEVuZ2luZWVyIOKAkyBBbmFseXRpY3MiLCJodGlkb2NpZCI6IkViXzMzR0ktNXprQUFBQUFBQUFBQUE9PSIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVVWek4ycE9WSEp0V2pac2VubDVNVE5IVGxCUmNqTjZhakJLUjJ0c2JqaG5iM2hSWW1FdFQxVk1TR04xUXpWQlUxVjFjRVZTVDJ4S2JuSndObWhmV0hJeVpVVlBUbFpYWjA1UFdFbFlaWFIzY0ZFMExUVlZYekIyU2psd2NYaE1MV3h5UmtwSVdGSTBValk0VWtnMVlVOVVNMm95ZGxRd1ZsaHhRbDlPTTBKaGJETjNjRGt0VFdjeWVHMWpXR1JUTTBnMFRsRjBlRUpEWkRod1lWUTBlSGhJY0habFJtMDFWalJIVms5clgzcG5ZMkpUVFZKM0VoY3dTMVUzV2twVVNFNDNOMFpyVUVsUU1sOXBUQzFCTkJvaVFVOHRNSEpzTm0wd1gxSnRhVjlhUjBsRVZrcExiVXR1TmpWS2VtdDFkRTV4ZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18yIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFNhbGFyeS5jb20iLCJsaW5rIjoiaHR0cHM6Ly93d3cuc2FsYXJ5LmNvbS9qb2IvdmlzYS9zdGFmZi1kYXRhLWVuZ2luZWVyLWFuYWx5dGljcy9qMjAyMzAyMTQyMzIxNDkwNDY5MjM2P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="}, {"title": "Data Engineer", "company_name": "Maersk GSC (India) P.L.", "location": "  United States   ", "via": "via Salary.com", "description": "Data engineers are responsible for building data products. They extract data from multiple systems, build reliable data pipelines and transform data so that it can easily be analyzed or consumed by downstream consumers and systems. Data Engineers work accross data sources and sometimes business domains to explore and integrate data to develop new data prodcuts. Data Engineers also have the... ability to visualize and analyze data in dashboards or build custom data applications. Are able to deliver data solutions from start to finish, including testing and deployment. Understand data models and are able to enhance and relate ongoing work to it. Are able to translate business needs to technical solution. A.P. Moller - Maersk is an integrated container logistics company working to connect and simplify its customer's supply chains. As the global leader in shipping services, the company operates in 130 countries and employs roughly 70,000 people. With simple end-to-end offering of products and digital services, seamless customer engagement and a superior end-to-end delivery network, Maersk enables its customers to trade and grow by transporting goods anywhere - all over the world. For more information click here. All the way", "job_highlights": [{"title": "Responsibilities", "items": ["Data engineers are responsible for building data products", "They extract data from multiple systems, build reliable data pipelines and transform data so that it can easily be analyzed or consumed by downstream consumers and systems", "Data Engineers work accross data sources and sometimes business domains to explore and integrate data to develop new data prodcuts", "Data Engineers also have the ability to visualize and analyze data in dashboards or build custom data applications", "Are able to deliver data solutions from start to finish, including testing and deployment", "Understand data models and are able to enhance and relate ongoing work to it"]}], "related_links": [{"link": "https://www.google.com/search?ucbcb=1&hl=en&q=Maersk+GSC+(India)+P.L.&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCMsK", "text": "See web results for Maersk GSC (India) P.L."}], "extensions": ["4 days ago", "Full-time", "No degree mentioned"], "detected_extensions": {"posted_at": "4 days ago", "schedule_type": "Full-time"}, "job_id": "eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJRMzhXWW1Nbnp1SUFBQUFBQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFdUlCQ3FJQlFVVnpOMnBPVWpCbU9YWnBRbHAzY21OTFYwMXViWGxtVG5KQ1RtVmxYM1IwWVV0bVVVeE5RbE54TXpsaFFucHNkMTlQVDJ0WlJtMWlUVkJpTmtsV2FYVTRhbGxuZG5aRmREWnlNbFZ5UkU5QldHTXhObE5DY1U5a1lXTm9TME4wTkd0elJGWkhZVE5oZUZWck9HVmxOVWxyZDJjd05raHFOMU5ZZWpaUFgySXhZVGMwTm1WME5HeFBSQzAyV0RabWMzcFNjSEoyY2w5WFJ6RjJOVEUxVGpWUkVoY3dTMVUzV2twVVNFNDNOMFpyVUVsUU1sOXBUQzFCTkJvaVFVOHRNSEpzTldWNldXZGhWbFpyWlhCRWFrUkNOamRtV21SdmIxUmlibHB0UVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY180IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFNhbGFyeS5jb20iLCJsaW5rIjoiaHR0cHM6Ly93d3cuc2FsYXJ5LmNvbS9qb2IvbWFlcnNrLWdzYy1pbmRpYS1wLWwvZGF0YS1lbmdpbmVlci9qMjAyMzAzMTUxNTM1MjE3MDQzODcxP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="}, {"title": "Big Data Engineer Inter India", "company_name": "Veridic Solutions", "location": "  United States   ", "via": "via Jooble", "description": "Job description\n\u2022 3+ years of experience in Big Data technologies\n\u2022 Experience in designing and implementing data pipelines...\n\u2022 Hands on experience in Hadoop Ecosystem (Spark, Scala, Hive, PIG )\n\u2022 Flair for data, schema, data model, how to bring efficiency in big data related life cycle\n\u2022 Good understanding of streaming applications\n\u2022 Basic understanding of Azure Data bricks\n\u2022 Basic understanding of SQL or NoSQL DBs\n\u2022 Good communications skill\n\nYears of Experience:3 to 6 Years\n\nLocation -Hyderabad, Gurgaon Bangalore\n\nNotice Period - Immediate to 30 days", "job_highlights": [{"title": "Qualifications", "items": ["3+ years of experience in Big Data technologies", "Experience in designing and implementing data pipelines", "Hands on experience in Hadoop Ecosystem (Spark, Scala, Hive, PIG )", "Basic understanding of Azure Data bricks", "Basic understanding of SQL or NoSQL DBs", "Good communications skill"]}], "related_links": [{"link": "https://www.google.com/search?ucbcb=1&hl=en&q=Veridic+Solutions&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCIcL", "text": "See web results for Veridic Solutions"}], "extensions": ["5 days ago", "Full-time", "No degree mentioned"], "detected_extensions": {"posted_at": "5 days ago", "schedule_type": "Full-time"}, "job_id": "eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBFbmdpbmVlciBJbnRlciBJbmRpYSIsImh0aWRvY2lkIjoiS3ZfZUFfbzlJdTBBQUFBQUFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVVZ6TjJwT1VqVkxkakJYUm1SaU9WOUJhVFpKVTBGRUxTMXRTMU4wY0V0dWJVcGtNMVpUZUVaa1RFdG5lVFJKV1dOcFZFVkVlVGcyWmkxNmIwdE5lR0k1ZEZOTFNWTmtkR1JFVm0xelRuTm1XRVU0VTFGaVltaFRWQzE1TWtNNU16TndXV0l3ZUV4UU1UZDZTM0ZQUjFSWFJTMXhPRU15YUhsc2FWUTNSR0ZpTVRrMVIwVTJMVmhmUTFGaFR6TjRkMG90UW5aa0xVNTRVbEJ3ZFVkR1VrTlZiVWRuVkRrelZGSXdNemN5V21GTWIwaFlWMnBORWhjd1MxVTNXa3BVU0U0M04wWnJVRWxRTWw5cFRDMUJOQm9pUVU4dE1ISnNORE15UXkxMlNTMDBUWE5NY1ZOU1dYVnRNV0pzUlVsTk9VOXBRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSm9vYmxlIiwibGluayI6Imh0dHBzOi8vam9vYmxlLm9yZy9qZHAvLTYzMjgwMDc3OTIwNzYyODMwODUvQmlnLURhdGEtRW5naW5lZXItSW50ZXItSW5kaWEtSW5kaWFuYT91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"}, {"title": "Lead Engineer, Oracle Data Engineering", "company_name": "Raymond James Financial", "location": "  St. Petersburg, FL   ", "via": "via Glassdoor", "description": "The Lead Data Engineer works as part of the Enterprise Data Team and will be responsible for developing Data Integration solutions in support of a critical data platform. The Lead Data Engineer plays a key role in the journey of Raymond James to develop a leading Wealth Management Platform. This position will have extensive contact with multiple application development teams and other shared... services teams. The core team is based out of our headquarters in St. Petersburg, FL, however we are open to our Denver, CO site as well (Hybrid).\n\nEssential Duties and Responsibilities:\n\u2022 Responsible for developing highly optimized low latency Data Integration solutions.\n\u2022 Responsible for writing code which conforms to standards and best practices and is highly efficient.\n\u2022 Responsible for understanding deeply the end to end data requirements, application and service requirements and designing end to end data solutions.\n\u2022 Responsible for periodically supporting a 24x7 production data platform which is consumed by multiple enterprise applications.\n\u2022 Work with other Data Engineers, Development and Production DBA\u2019s as part of Database Design and Development.\n\u2022 Performs other duties and responsibilities as assigned.\n\nQualifications\n\nKnowledge, Skills, and Abilities:\n\nKnowledge of:\n\u2022 Experience with Oracle Data Integrator or Informatica is a plus.\n\u2022 Experience with AWS is a plus.\n\u2022 Experience with Search Platforms like SOLR is a plus.\n\u2022 Understanding of Master Data Management (MDM) principles is a plus.\n\u2022 Financial Services Industry knowledge is a plus.\n\nSkill in:\n\u2022 Must have relevant experience in various database platforms, ETL solutions/products, ETL Architecture.\n\u2022 Expert level experience with Oracle(or similar DB platforms), ETL Architecture and Development.\n\u2022 Expert Level experience in Performance Optimization of ETL and Database (Oracle \u2013 SQL, PLSQL or similar)\n\u2022 Expert level experience with efficient Data Integration patterns/technologies.\n\u2022 Experience in building low latency Data Integration solutions.\n\nAbility to:\n\u2022 Identify and understand issues, problems and opportunities; compare data from different sources to draw conclusions.\n\u2022 Clearly convey information and ideas through a variety of media to individuals or groups in a manner that engages the audience and helps them understand and retain the message.\n\u2022 Use effective approaches for choosing a course of action or developing appropriate solutions; recommend or take action that is consistent with available facts, constraints and probable consequences.\n\u2022 Demonstrate a satisfactory level of technical and professional skill or knowledge in position-related areas; remains current with developments and trends in areas of expertise.\n\u2022 Develop and use collaborative relationships to facilitate the accomplishment of work goals.\n\u2022 Make internal and external clients and their needs a primary focus of actions; develop and sustain productive client relationships.\n\u2022 Occasionally work a non-standard shift including nights and/or weekends and/or have on-call responsibilities.\n\nEducation/Previous Experience:\n\u2022 Minimum of a Bachelor\u2019s degree in Computer Science, MIS or related degree and five (5) years of relevant development or engineering experience or combination of education, training and experience.\n\nLicenses/Certifications:\n\u2022 None required.\n\nRaymond James Guiding Behaviors\n\nAt Raymond James our associates use five guiding behaviors (Develop, Collaborate, Decide, Deliver, Improve) to deliver on the firm's core values of client-first, integrity, independence and a conservative, long-term view.\n\nWe expect our associates at all levels to:\n\u2022 Grow professionally and inspire others to do the same\n\u2022 Work with and through others to achieve desired outcomes\n\u2022 Make prompt, pragmatic choices and act with the client in mind\n\u2022 Take ownership and hold themselves and others accountable for delivering results that matter\n\u2022 Contribute to the continuous evolution of the firm\n\nAt Raymond James \u2013 we honor, value, respect the uniqueness, experiences, and backgrounds of all of our Associates. When associates bring their best authentic self, our organization, clients and communities thrive, it is part of our part of our people-first culture. The Company is an equal opportunity employer and makes all employment decisions on the basis of merit and business needs.\n\nJob Technology\n\nPrimary Location US-FL-St. Petersburg-Saint Petersburg\n\nOther Locations US-FL-St. Petersburg-Saint Petersburg, US-CO-Denver-Denver\n\nOrganization Technology\n\nSchedule Full-time\n\nShift Day Job\n\nTravel Yes, 5 % of the Time\n\nSalary Range: CO, NY, CA, WA (based on Education, Work Experience, and Geographic Location) $100-150k\n\nEligible for Discretionary Bonus Yes\n\n#LI-NM1", "job_highlights": [{"title": "Qualifications", "items": ["Must have relevant experience in various database platforms, ETL solutions/products, ETL Architecture", "Expert level experience with Oracle(or similar DB platforms), ETL Architecture and Development", "Expert Level experience in Performance Optimization of ETL and Database (Oracle \u2013 SQL, PLSQL or similar)", "Expert level experience with efficient Data Integration patterns/technologies", "Experience in building low latency Data Integration solutions", "Identify and understand issues, problems and opportunities; compare data from different sources to draw conclusions", "Clearly convey information and ideas through a variety of media to individuals or groups in a manner that engages the audience and helps them understand and retain the message", "Use effective approaches for choosing a course of action or developing appropriate solutions; recommend or take action that is consistent with available facts, constraints and probable consequences", "Demonstrate a satisfactory level of technical and professional skill or knowledge in position-related areas; remains current with developments and trends in areas of expertise", "Minimum of a Bachelor\u2019s degree in Computer Science, MIS or related degree and five (5) years of relevant development or engineering experience or combination of education, training and experience"]}, {"title": "Responsibilities", "items": ["The Lead Data Engineer works as part of the Enterprise Data Team and will be responsible for developing Data Integration solutions in support of a critical data platform", "The Lead Data Engineer plays a key role in the journey of Raymond James to develop a leading Wealth Management Platform", "Responsible for developing highly optimized low latency Data Integration solutions", "Responsible for writing code which conforms to standards and best practices and is highly efficient", "Responsible for understanding deeply the end to end data requirements, application and service requirements and designing end to end data solutions", "Responsible for periodically supporting a 24x7 production data platform which is consumed by multiple enterprise applications", "Work with other Data Engineers, Development and Production DBA\u2019s as part of Database Design and Development", "Performs other duties and responsibilities as assigned", "Develop and use collaborative relationships to facilitate the accomplishment of work goals", "Make internal and external clients and their needs a primary focus of actions; develop and sustain productive client relationships", "Work with and through others to achieve desired outcomes", "Make prompt, pragmatic choices and act with the client in mind", "Take ownership and hold themselves and others accountable for delivering results that matter"]}, {"title": "Benefits", "items": ["Salary Range: CO, NY, CA, WA (based on Education, Work Experience, and Geographic Location) $100-150k", "Eligible for Discretionary Bonus Yes"]}], "related_links": [{"link": "http://www.raymondjames.com/", "text": "raymondjames.com"}, {"link": "https://www.google.com/search?ucbcb=1&hl=en&q=Raymond+James+Financial&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCMoL", "text": "See web results for Raymond James Financial"}], "extensions": ["2 days ago", "Full-time"], "detected_extensions": {"posted_at": "2 days ago", "schedule_type": "Full-time"}, "job_id": "eyJqb2JfdGl0bGUiOiJMZWFkIEVuZ2luZWVyLCBPcmFjbGUgRGF0YSBFbmdpbmVlcmluZyIsImh0aWRvY2lkIjoibGxRb2tjMlF2QjBBQUFBQUFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXJjQ0N2Y0JRVVZ6TjJwT1ZHRm1VRVl3U1V3eloyVmxOakl3TUdJM1VFWkdUM3BJWHpGUVIxRnRiMkpTVkRSMU9XSXRiRmw2YldweFYySlpka1F0YVdzNGJYbEpRMFJyVUhKb1ExRmFWMlZRVGpsSFltTk1XbGd6VEVacFMyUkRWaTF3WjJoRlpVUnZPRzl1TmtSVFdWbzJSMXBrUTJwWlRqUkdPVkZzY25NMGVraE5aMHRXT0dsVVIwbzFZVjltV2pOcWJVcE5OVkUzYUVSb1RGcG5TRnBWVXpaVlpGaGhiM05PVERCMVl6WlJTMFZ2WnpGMVNrWnhSVWxOV2tveVJYVTJTSGRCWTFONVlUWjVaVEZ5WlcxMGN6bFFhelE1U2tabmMzZGZSRmcyUzNRd1lVbHFSM2syZURRMVpWWlVibDlaWTA4MFVYaHJhVzF4WnhJWE1FdFZOMXBLVkVoT056ZEdhMUJKVURKZmFVd3RRVFFhSWtGUExUQnliRFp6TTFwc2JYcGZOak5YYzAwMmJqaEZZbk16TkZoSlFqTXpjWGMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY182IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEdsYXNzZG9vciIsImxpbmsiOiJodHRwczovL3d3dy5nbGFzc2Rvb3IuY29tL2pvYi1saXN0aW5nL2xlYWQtZW5naW5lZXItZGF0YS1lbmdpbmVlcmluZy1yYXltb25kLWphbWVzLWZpbmFuY2lhbC1KVl9JQzExNTQ0MjFfS08wLDMwX0tFMzEsNTQuaHRtP2psPTEwMDg0NzEyMTU2MzdcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"}, {"title": "Data Engineer | Analytics | Retail, Media & Hi-Tech", "company_name": "EXL Services", "location": "  Jersey City, NJ   ", "via": "via Glassdoor", "description": "Overview\n\nEXL (NASDAQ: EXLS) is a leading operations management and analytics company that designs and enables agile, customer-centric operating models to help clients improve their revenue growth and profitability. Our delivery model provides market-leading business outcomes using EXL\u2019s proprietary Business EXLerator Framework\u2122, cutting-edge analytics, digital transformation and domain... expertise. At EXL, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 32,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), South America, Australia and South Africa.\n\nEXL Analytics provides data-driven, action-oriented solutions to business problems through statistical data mining, cutting edge analytics techniques and a consultative approach. Leveraging proprietary methodology and best-of-breed technology, EXL Analytics takes an industry-specific approach to transform our clients\u2019 decision making and embed analytics more deeply into their business processes. Our global footprint of nearly 2,000 data scientists and analysts assist client organizations with complex risk minimization methods, advanced marketing, pricing and CRM strategies, internal cost analysis, and cost and resource optimization within the organization. EXL Analytics serves the insurance, healthcare, banking, capital markets, utilities, retail and e-commerce, travel, transportation and logistics industries.\n\nPlease visit www.exlservice.com for more information about EXL Analytics.\n\nResponsibilities:\n\u2022 Emphasis on end-to-end delivery of analysis and guiding junior staff\n\u2022 Collaborate with client stakeholders to analyze and synthesize the client data to meet the business objective, reporting dashboard, and descriptive/predictive/prescriptive analytic requirements\n\u2022 Leverage best practices and industry leading tools and technologies to profile data, develop efficient ingestion, and build semantic data layers\n\u2022 Design data models and solutions for analytical and reporting use cases\n\u2022 Expected to build the foundational analytics platform components, manage cloud components and help in designing a cost model to monitor cloud usages\n\u2022 Manage the build and architecture of next-generation Big Data Machine Learning framework developed on a group of core Hadoop technologies\n\u2022 Contribute and manage design of highly scalable and extensible data platform including but not limited to RDBMS / Big Data / Cloud, which enables industrializing collection, storage, modeling, and analysis of massive data sets from heterogeneous channels\n\u2022 Reformulate highly technical information into concise, understandable terms for presentations\n\nQualifications:\n\u2022 Master\u2019s or Bachelor's degree in Data Science, Computer Engineering, Math, Statistics, Economics or related analytics field from top-tier universities with strong record of achievement\n\u2022 3-5 years of consulting, analytics delivery experience with solid data engineering skills and an entrepreneurial, hands-on approach\n\u2022 Very strong analytical skills with the demonstrated ability to research and make decisions based on the day-to-day and complex customer problems required\n\u2022 Hand on knowledge of traditional relational data warehouse technologies, such as Oracle, Teradata, or DB2 SQL, including Analytical SQL functions\n\u2022 Experience in data architecture and data modeling, including creating Semantic Layer Data Models, Big data platforms including Hadoop (preferably Azure or GCP) and technologies including Spark, Airflow, Kafka, Hbase, Pig, NoSQL, etc.\n\u2022 Cloud components, including cluster management, Kubernetes, or other containerized services, storage, and workspace management\n\u2022 Preferred domain expertise in Healthcare, Pharma, Retail or Media\n\u2022 Experience in Machine Learning or NLP, such as Scikit-Learn, SpaCity, Pytorch, or Spark NLP is desirable\n\u2022 Prior experience in management consulting and/or analytics based consulting is desirable\n\nWhat we offer:\n\u2022 EXL Analytics offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world class analytics consultants. You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth\n\u2022 Analytics requires different skill sets at different levels within the organization. At EXL Analytics, we invest heavily in training you in all aspects of analytics as well as in leading analytical tools and techniques.\n\u2022 We provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors.\n\u2022 Sky is the limit for our team members. The unique experiences gathered at EXL Analytics sets the stage for further growth and development in our company and beyond.\n\nEEO/Minorities/Females/Vets/Disabilities", "job_highlights": [{"title": "Qualifications", "items": ["Master\u2019s or Bachelor's degree in Data Science, Computer Engineering, Math, Statistics, Economics or related analytics field from top-tier universities with strong record of achievement", "3-5 years of consulting, analytics delivery experience with solid data engineering skills and an entrepreneurial, hands-on approach", "Very strong analytical skills with the demonstrated ability to research and make decisions based on the day-to-day and complex customer problems required", "Hand on knowledge of traditional relational data warehouse technologies, such as Oracle, Teradata, or DB2 SQL, including Analytical SQL functions", "Experience in data architecture and data modeling, including creating Semantic Layer Data Models, Big data platforms including Hadoop (preferably Azure or GCP) and technologies including Spark, Airflow, Kafka, Hbase, Pig, NoSQL, etc", "Cloud components, including cluster management, Kubernetes, or other containerized services, storage, and workspace management", "Analytics requires different skill sets at different levels within the organization"]}, {"title": "Responsibilities", "items": ["Emphasis on end-to-end delivery of analysis and guiding junior staff", "Collaborate with client stakeholders to analyze and synthesize the client data to meet the business objective, reporting dashboard, and descriptive/predictive/prescriptive analytic requirements", "Leverage best practices and industry leading tools and technologies to profile data, develop efficient ingestion, and build semantic data layers", "Design data models and solutions for analytical and reporting use cases", "Expected to build the foundational analytics platform components, manage cloud components and help in designing a cost model to monitor cloud usages", "Manage the build and architecture of next-generation Big Data Machine Learning framework developed on a group of core Hadoop technologies", "Contribute and manage design of highly scalable and extensible data platform including but not limited to RDBMS / Big Data / Cloud, which enables industrializing collection, storage, modeling, and analysis of massive data sets from heterogeneous channels", "Reformulate highly technical information into concise, understandable terms for presentations"]}], "related_links": [{"link": "http://www.exlservice.com/", "text": "exlservice.com"}, {"link": "https://www.google.com/search?ucbcb=1&hl=en&q=EXL+Services&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCI4M", "text": "See web results for EXL Services"}], "extensions": ["21 days ago", "Full-time"], "detected_extensions": {"posted_at": "21 days ago", "schedule_type": "Full-time"}, "job_id": "eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIHwgQW5hbHl0aWNzIHwgUmV0YWlsLCBNZWRpYSBcdTAwMjYgSGktVGVjaCIsImh0aWRvY2lkIjoiYV8tRjVsa2FzM01BQUFBQUFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXFJQ0N1SUJRVVZ6TjJwT1VsQnNaMlI0WmtNeVpEVjVOSGgzYTJnek16SkdTbE5CVGpobmNsZGxiV3N3Y1UxUVZEZEJOa1ZxVFVKclNHTktNbWMzUlhOT1VYTlVVbmxaTW04M2FGQkJOVFpNZEhwQlJGaHljbXhyTTFOd2FITm5SVTVSVERneVJISkRhbFIzVmtKeWFpMU9NbEZ6VVY5S1YwdFpUVEZGVlRCTldGWlFPRlpTTlVWNFVVNUlPSE5YWkU5ck1sTjFWbGhHTFZCaGEyZFpOWFJ2VEZVMU1HdFNYM04xWVZwUVVVeHJkbHBQUlcxamVIQkpURzVMVDIxVmRGbG1ORU40UlhGcmRUSkpZbXAzVldSc1dXeEpkVEl5U0Vkb2VuRkdWR0pWV21KbGIyNXVRUklYTUV0Vk4xcEtWRWhPTnpkR2ExQkpVREpmYVV3dFFUUWFJa0ZQTFRCeWJEZGlWWGxpWVU5Q2NtRjJkRzVRUnpOWmNrVkVNMmh6YzJWaFJrRSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzgiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gR2xhc3Nkb29yIiwibGluayI6Imh0dHBzOi8vd3d3LmdsYXNzZG9vci5jb20vam9iLWxpc3RpbmcvZGF0YS1lbmdpbmVlci1hbmFseXRpY3MtcmV0YWlsLW1lZGlhLWFuZC1oaS10ZWNoLWV4bC1zZXJ2aWNlLUpWX0lDMTEyNjgxOV9LTzAsNDhfS0U0OSw2MC5odG0/amw9MTAwNjkxNTQ0NDM1NVx1MDAyNnV0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="}, {"title": "Senior Specialist, Federal Data Engineer", "company_name": "KPMG", "location": "  Jacksonville, FL   ", "via": "via LocalJobs.com", "description": "\u2022 *Business Title:** Senior Specialist, Federal Data Engineer\n\u2022 *Requisition Number:** 97172 - 23\n\u2022 *Function:** Advisory...\n\u2022 *Area of Interest:**\n\u2022 *State:** FL\n\u2022 *City:** Jacksonville\n\u2022 *Description:**\n\nThe KPMG Advisory practice is currently our fastest growing practice. We are seeing tremendous client demand, and looking forward we don't anticipate that slowing down. In this ever-changing market environment, our professionals must be adaptable and thrive in a collaborative, team-driven culture. At KPMG, our people are our number one priority. With a wealth of learning and career development opportunities, a world-class training facility and leading market tools, we make sure our people continue to grow both professionally and personally. If you're looking for a firm with a strong team connection where you can be your whole self, have an impact, advance your skills, deepen your experiences, and have the flexibility and access to constantly find new areas of inspiration and expand your capabilities, then consider a career in Advisory.\n\nKPMG is currently seeking an Senior Specialist for our Federal Advisory practice.\n\nResponsibilities:\n\n+ Collaborate with multi-disciplinary and cross-functional tams to provide data analytics support for our federal client in the development and operation of program integrity and financial oversight functions of the government marketplaces and marketplace-related premium stabilization programs established under the Affordable Care Act. The engagement includes assistance with quality assurance, data quality analysis and compliance reviews\n\n+ Work with clients and team leads to discover data sources in client cloud environment, create data requests; utilize the ETL process to ingest and enrich structured and unstructured data; design, implement, ad test data processing pipelines, and data mining/data science algorithms on a variety of hosted settings\n\n+ Rapidly learn and understand client business processes by reviewing technical documentation, business catalogs, white papers and deep dive into KPMG's client data to better understand the relationship between datasets, client systems and data sources\n\n+ Contribute in developing dashboards, UI and interactive tools to support clients to turn their data into actionable insights and reproducible reports\n\nQualifications:\n\n+ Minimum three years of experience in developing high-quality scripts and queries, data pipelines, ETL, visualizations, and visualization dashboards\n\n+ Bachelor's degree or Master's degree from an accredited college/university\n\n+ Proficiency with programming languages such as Python, Scala and R and their open source packages/libraries\n\n+ Market-leading fluency in Oracle databases, Linux/Unix tools, Shell Script/Bash and Job schedulers such as Cron job\n\n+ Expertise with development tools and team methodologies (Agile, Git, test driven environment, CI/CD release management)\n\n+ Experience with large-scale big data methods (Hadoop stack, Cloud, Kubernetes)\n\n+ Familiarity with cloud services and tools particularly AWS native services required for designing and implanting reproducible reports, big data processing, cloud database tools (RDS, Aurora, Redshift, EMR etc) is a plus\n\n+ Basic knowledge on government health market, Affordable Care Act, public health policy is a plus\n\n+ Ability to obtain a U.S. Federal government security clearance within a reasonable period of time, which requires U.S.citizenship\n\nKPMG complies with all local/state regulations in regards to displaying salary ranges. If required, the salary range(s) are displayed below and are specifically for those potential hires who will perform work in or reside in the location(s) listed, if selected for the role. Any offered salary is determined based on internal equity, internal salary ranges, market data, ranges, applicant's skills and prior relevant experience, certain degrees and certifications (e.g. JD, technology), for example.\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link ( https://assets.kpmg.com/content/dam/kpmg/us/pdf/2018/09/eeo.pdf) contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.\n\nKPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site). /\n\u2022 *GL:** 5\n\u2022 *GF:** 15306", "job_highlights": [{"title": "Qualifications", "items": ["Minimum three years of experience in developing high-quality scripts and queries, data pipelines, ETL, visualizations, and visualization dashboards", "Bachelor's degree or Master's degree from an accredited college/university", "Proficiency with programming languages such as Python, Scala and R and their open source packages/libraries", "Market-leading fluency in Oracle databases, Linux/Unix tools, Shell Script/Bash and Job schedulers such as Cron job", "Expertise with development tools and team methodologies (Agile, Git, test driven environment, CI/CD release management)", "Experience with large-scale big data methods (Hadoop stack, Cloud, Kubernetes)", "Ability to obtain a U.S. Federal government security clearance within a reasonable period of time, which requires U.S.citizenship"]}, {"title": "Responsibilities", "items": ["Collaborate with multi-disciplinary and cross-functional tams to provide data analytics support for our federal client in the development and operation of program integrity and financial oversight functions of the government marketplaces and marketplace-related premium stabilization programs established under the Affordable Care Act", "The engagement includes assistance with quality assurance, data quality analysis and compliance reviews", "Work with clients and team leads to discover data sources in client cloud environment, create data requests; utilize the ETL process to ingest and enrich structured and unstructured data; design, implement, ad test data processing pipelines, and data mining/data science algorithms on a variety of hosted settings", "Rapidly learn and understand client business processes by reviewing technical documentation, business catalogs, white papers and deep dive into KPMG's client data to better understand the relationship between datasets, client systems and data sources", "Contribute in developing dashboards, UI and interactive tools to support clients to turn their data into actionable insights and reproducible reports"]}], "related_links": [{"link": "http://www.kpmg.com/", "text": "kpmg.com"}, {"link": "https://www.google.com/search?ucbcb=1&hl=en&q=KPMG&sa=X&ved=0ahUKEwiU75u38q3-AhW-IkQIHVv8Au8QmJACCNAM", "text": "See web results for KPMG"}], "extensions": ["21 days ago", "Full-time"], "detected_extensions": {"posted_at": "21 days ago", "schedule_type": "Full-time"}, "job_id": "eyJqb2JfdGl0bGUiOiJTZW5pb3IgU3BlY2lhbGlzdCwgRmVkZXJhbCBEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJ6bWhDT0lpMDdJc0FBQUFBQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVVnpOMnBPVkU1QlNuRjVhR2RFU0hCelVXUk9UVWxzWW1aRVptVkxPRXBuZUd0VmFqUlRVVWRDTlhGc1ozSm1jelEzTFU0MGNrOUxaMGgxTlRCbVVtczVlV2xXUmxKYWNXaHRSa0pvY1MxWU1tMTJXbW8xYkhCbU5HcGZVVEJYTUZodmNXRlVOM2RZYms5NE1rVkNaRzF6TFdSNk4yUnNkMWt3VjNKTFZWWm1URkZMVldWQ1lYVXlkRTQ0VFRCcFZVcGhhRmhwUVdKa1JuVjNSM2h5ZDBKMmNqZHZTRTFIUkhZMVYxSjJjSGR4TmpSTWNIbGxUVWxRUWxOWFUzUnJVMFJCYm5wWE1FZHhSVjlNRWhjd1MxVTNXa3BVU0U0M04wWnJVRWxRTWw5cFRDMUJOQm9pUVU4dE1ISnNOVWRTYm1OdU9FbG1NMDlFYkZjMk1YWkROMDAzVGtwYWQyVnVRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEwIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIExvY2FsSm9icy5jb20iLCJsaW5rIjoiaHR0cHM6Ly93d3cubG9jYWxqb2JzLmNvbS9qb2IvamFja3NvbnZpbGxlLWZsLXNlbmlvci1zcGVjaWFsaXN0LWZlZGVyYWwtZGF0YS1lbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"}], "chips": [{"type": "Title", "param": "job_family_1", "options": [{"text": "All"}, {"text": "Data engineer", "value": "data engineer"}, {"text": "Senior specialist", "value": "senior specialist"}, {"text": "Lead engineer", "value": "lead engineer"}]}, {"type": "Location", "param": "city", "options": [{"text": "All"}, {"text": "Jacksonville, FL", "value": "66_O8Ra35Yjix_yWOH3NxA=="}, {"text": "Jersey City, NJ", "value": "3a-_JdJQwonZJc2iE_BJAg=="}, {"text": "St. Louis, MO", "value": "-Y7t-qm02Idb4Lsiyuo5vg=="}, {"text": "St. Petersburg, FL", "value": "Qao6aWPmwoj_i9S8A0DMBA=="}]}, {"type": "Date posted", "param": "date_posted", "options": [{"text": "All"}, {"text": "Past day", "value": "today"}, {"text": "Past 3 days", "value": "3days"}, {"text": "Past week", "value": "week"}, {"text": "Past month", "value": "month"}]}, {"type": "Requirements", "param": "requirements", "options": [{"text": "All"}, {"text": "No degree", "value": "no_degree"}, {"text": "No experience", "value": "no_experience"}, {"text": "Under 3 years of experience", "value": "years3under"}, {"text": "3+ years of experience", "value": "years3plus"}]}, {"type": "Type", "param": "employment_type", "options": [{"text": "All"}, {"text": "Full-time", "value": "FULLTIME"}, {"text": "Contractor", "value": "CONTRACTOR"}, {"text": "Internship", "value": "INTERN"}, {"text": "Part-time", "value": "PARTTIME"}]}, {"type": "Company type", "param": "industry.id", "options": [{"text": "All"}, {"text": "Consulting", "value": "/business/naics2007/5416"}, {"text": "Finance", "value": "/business/naics2007/52"}, {"text": "Computer Services", "value": "/business/naics2007/5415"}]}, {"type": "Employer", "param": "organization_mid", "options": [{"text": "All"}, {"text": "KPMG", "value": "/m/0k2gt"}, {"text": "EXL Services", "value": "/m/02qhpd_"}, {"text": "Raymond James Financial", "value": "/m/03p31c0"}, {"text": "Visa", "value": "/m/01kqjn"}]}]}